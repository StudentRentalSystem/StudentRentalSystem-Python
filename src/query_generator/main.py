import sys
import os
import json
import threading
from queue import Queue

# --- é‡è¦ï¼šè§£æ±º Import è·¯å¾‘å•é¡Œ ---
current_dir = os.path.dirname(os.path.abspath(__file__))
src_dir = os.path.dirname(current_dir)
llm_data_parser_dir = os.path.join(src_dir, "llm_data_parser")

if src_dir not in sys.path:
    sys.path.append(src_dir)

if llm_data_parser_dir not in sys.path:
    sys.path.append(llm_data_parser_dir)
# -------------------------------

from llm_data_parser.config import LLMConfig, LLMMode
from llm_data_parser.client import LLMClient
from query_generator.app import MiniRagApp
from query_generator.settings import LLM_SERVER_ADDRESS, LLM_SERVER_PORT, LLM_MODEL_TYPE

# å˜—è©¦åŒ¯å…¥ API KEYï¼Œå¦‚æœ settings.py æ²’æœ‰é€™å€‹è®Šæ•¸å‰‡è¨­ç‚º None
try:
    from query_generator.settings import LLM_API_KEY
except ImportError:
    LLM_API_KEY = None


# === æ””æˆªå™¨ (Monkey Patch) ===
def install_spy(mini_rag_instance):
    try:
        client = getattr(mini_rag_instance, 'llm_client', None) or getattr(mini_rag_instance, 'client', None)
        if client:
            # æ³¨å…¥ API KEY åˆ°åŸæœ¬çš„ config (å¦‚æœæ˜¯é€é App åˆå§‹åŒ–)
            if LLM_API_KEY:
                client.config.api_key = LLM_API_KEY
                print(f"ğŸ”‘ å·²æ³¨å…¥ API Key åˆ° MiniRagApp Client")

            original_method = client.call_local_model

            def spy_call_local_model(prompt, *args, **kwargs):
                if "JSON" in prompt or "json" in prompt:
                    print(f"\n[ğŸ” SPY] æ””æˆªåˆ° Prompt è«‹æ±‚:\n{prompt[:100]}...")
                return original_method(prompt, *args, **kwargs)

            client.call_local_model = spy_call_local_model
            print("âœ… å·²å®‰è£å…§éƒ¨ç›£è½å™¨")
    except Exception as e:
        print(f"âš ï¸ å®‰è£ç›£è½å™¨å¤±æ•—: {e}")


def main():
    print(f"ğŸ”„ åˆå§‹åŒ–ç³»çµ±ä¸­...")
    print(f"ğŸ“ é€£ç·šç›®æ¨™: {LLM_SERVER_ADDRESS}:{LLM_SERVER_PORT} (Model: {LLM_MODEL_TYPE})")
    if LLM_API_KEY:
        print(f"ğŸ”‘ API Key: å·²è¼‰å…¥ ({LLM_API_KEY[:4]}***)")
    else:
        print(f"âš ï¸ API Key: æœªè¨­å®š (å¦‚æœé‡åˆ° 403 éŒ¯èª¤ï¼Œè«‹åœ¨ settings.py åŠ å…¥ LLM_API_KEY)")

    try:
        mini_rag = MiniRagApp()
        install_spy(mini_rag)
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±æ•—: {e}")
        return

    use_mongodb = True
    print("\nâœ¨ MiniRAG å•Ÿå‹•æˆåŠŸï¼")
    print("------------------------------------------------------")
    print("æŒ‡ä»¤èªªæ˜:")
    print("  [æ–‡å­—]   è¼¸å…¥ç§Ÿå±‹éœ€æ±‚æŸ¥è©¢")
    print("  rental   åˆ‡æ›ç‚º MongoDB ç§Ÿå±‹æŸ¥è©¢æ¨¡å¼ (é è¨­)")
    print("  others   åˆ‡æ›ç‚ºä¸€èˆ¬èŠå¤©æ¨¡å¼")
    print("  debug    [æ–°å¢] æ¸¬è©¦æ¨¡å‹åŸå§‹è¼¸å‡º (æª¢æŸ¥ JSON æ ¼å¼)")
    print("  exit     é›¢é–‹ç¨‹å¼")
    print("------------------------------------------------------")

    while True:
        try:
            mode_name = "ç§Ÿå±‹æœå°‹(MongoDB)" if use_mongodb else "ä¸€èˆ¬èŠå¤©(Chat)"
            prompt_text = f"\n[{mode_name}] è«‹è¼¸å…¥éœ€æ±‚: "
            user_query = input(prompt_text).strip()

            if not user_query:
                continue

            # æŒ‡ä»¤è™•ç†
            if user_query.lower() == "exit":
                break
            elif user_query.lower() == "others":
                use_mongodb = False
                print("ğŸ”€ å·²åˆ‡æ›è‡³ï¼šä¸€èˆ¬èŠå¤©æ¨¡å¼")
                continue
            elif user_query.lower() == "rental":
                use_mongodb = True
                print("ğŸ”€ å·²åˆ‡æ›è‡³ï¼šç§Ÿå±‹æœå°‹æ¨¡å¼")
                continue
            elif user_query.lower() == "debug":
                print("ğŸ› é€²å…¥åµéŒ¯æ¨¡å¼...")
                debug_q = input("   [Debug] è«‹è¼¸å…¥æ¸¬è©¦èªå¥ (ä¾‹å¦‚: ä¸€æˆ¿ä¸€å»³): ").strip()
                if not debug_q: continue

                print("   [Debug] æ­£åœ¨è«‹æ±‚æ¨¡å‹ç”Ÿæˆ...")
                print("   [Raw Output Start] -> ", end="", flush=True)

                debug_queue = Queue()
                debug_config = LLMConfig(
                    mode=LLMMode.CHAT,
                    token=LLM_API_KEY,
                    server_address=LLM_SERVER_ADDRESS,
                    server_port=LLM_SERVER_PORT,
                    model_type=LLM_MODEL_TYPE,
                    stream=True,
                    queue=debug_queue
                )

                # æ‰‹å‹•æ³¨å…¥ API Key
                if LLM_API_KEY:
                    debug_config.api_key = LLM_API_KEY

                debug_client = LLMClient(debug_config)
                test_prompt = f"è«‹å°‡ä»¥ä¸‹éœ€æ±‚è½‰æ›ç‚º MongoDB æŸ¥è©¢ JSON: {debug_q}ã€‚åªè¼¸å‡º JSONï¼Œä¸è¦åŒ…å« Markdownã€‚"

                worker = threading.Thread(target=lambda: debug_client.call_local_model(test_prompt))
                worker.start()

                full_response = ""

                while True:
                    data = debug_queue.get()

                    token = getattr(data, 'token', None)
                    if not token: token = getattr(data, 'text', None)
                    if not token: token = getattr(data, 'content', None)

                    if token:
                        print(token, end="", flush=True)
                        full_response += str(token)

                    if hasattr(data, 'completed') and data.completed:
                        if not full_response and hasattr(data, 'complete_text') and data.complete_text:
                            print(data.complete_text, end="", flush=True)
                            full_response += str(data.complete_text)
                        break

                worker.join()
                print("\n   [Raw Output End] <-")

                if "403" in full_response or "æ¬Šé™éŒ¯èª¤" in full_response:
                    print("ğŸ›‘ æ¬Šé™éŒ¯èª¤ï¼è«‹æª¢æŸ¥æ‚¨çš„ API Key è¨­å®šã€‚")
                elif not full_response.strip().startswith("{"):
                    print("âš ï¸  è¼¸å‡ºä¸æ˜¯ä»¥ '{' é–‹é ­ï¼Œå¯èƒ½åŒ…å«é–’èŠæ–‡å­—ã€‚")
                else:
                    print("âœ… æ ¼å¼çœ‹èµ·ä¾†æ­£ç¢ºã€‚")
                continue

            if use_mongodb:
                print("â³ æ­£åœ¨åˆ†æä¸¦ç”Ÿæˆè³‡æ–™åº«æŸ¥è©¢èªå¥...")
                json_response = mini_rag.get_mongodb_search_cmd_json(user_query)

                if json_response:
                    fixed_response = mini_rag.get_fixed_mongo_query_cmd(json_response)
                    print("\nâœ… ç”Ÿæˆçµæœ (å¯ç›´æ¥ç”¨æ–¼ MongoDB):")
                    print(json.dumps(fixed_response, ensure_ascii=False, indent=2))
                else:
                    print("âš ï¸  ç„¡æ³•è§£æç‚ºæœ‰æ•ˆçš„ JSON æŸ¥è©¢ã€‚")

            else:
                print("ğŸ’¬ AI å›æ‡‰: ", end="", flush=True)
                stream_queue = Queue()
                chat_config = LLMConfig(
                    mode=LLMMode.CHAT,
                    server_address=LLM_SERVER_ADDRESS,
                    server_port=LLM_SERVER_PORT,
                    model_type=LLM_MODEL_TYPE,
                    stream=True,
                    queue=stream_queue
                )
                if LLM_API_KEY:
                    chat_config.api_key = LLM_API_KEY

                chat_client = LLMClient(chat_config)
                worker = threading.Thread(target=lambda: chat_client.call_local_model(user_query))
                worker.start()

                while True:
                    data = stream_queue.get()
                    token = getattr(data, 'token', None)
                    if token:
                        print(token, end="", flush=True)
                    if data.completed:
                        break
                print()
                worker.join()

        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç¨‹å¼ä¸­æ–·")
            break
        except Exception as e:
            print(f"\nâŒ ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()

    print("ğŸ‘‹ å†è¦‹ï¼")


if __name__ == "__main__":
    main()